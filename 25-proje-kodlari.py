# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18HjbKwy9tSEJgi7PzKIQjSe3ZaXeQKxj
"""



!pip install datasets



import os
import torch
import librosa
import numpy as np
from datasets import Dataset
from transformers import EarlyStoppingCallback, Wav2Vec2FeatureExtractor, HubertForSequenceClassification, TrainingArguments, Trainer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc


import time
import matplotlib.pyplot as plt
from sklearn.preprocessing import label_binarize


from google.colab import drive
drive.mount('/content/drive')

#dataset_root = '/content/drive/MyDrive/Dataset/guitar_dataset_test'
#dataset_root = '/content/drive/MyDrive/Dataset/dataset_tests'
#dataset_root = '/content/drive/MyDrive/Dataset/guitar_dataset'
dataset_root = '/content/drive/MyDrive/Dataset/dataset_sample'




import logging
logging.basicConfig(level=logging.INFO, force=True)




if __name__ == "__main__":
    # Définir le chemin de la racine de votre dataset
    #dataset_root = 'dataset/guitar dataset'
    #dataset_root = 'dataset/guitar_dataset_test'



    # Vérifier la disponibilité de GPU
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Utilisation de l'appareil : {device}")

    # 1. Préparation des données
    def load_audio_files(dataset_root):

        data = []
        labels = []

        note_folders = [folder for folder in os.listdir(dataset_root) if os.path.isdir(os.path.join(dataset_root, folder))]

        for note_folder in note_folders:
            note_path = os.path.join(dataset_root, note_folder)
            wav_files = [f for f in os.listdir(note_path) if f.endswith('.wav')]

            for wav_file in wav_files:
                file_path = os.path.join(note_path, wav_file)
                data.append(file_path)
                labels.append(note_folder.upper())  # Utiliser le nom du dossier comme label

        return data, labels

    audio_paths, labels = load_audio_files(dataset_root)

    # 2. Encodage des labels
    label_encoder = LabelEncoder()
    encoded_labels = label_encoder.fit_transform(labels)

    # Sauvegarder les classes pour référence future
    classes = label_encoder.classes_
    print(f"Classes détectées : {classes}")

    # 3. Séparer en ensembles d'entraînement et de test
    train_paths, test_paths, train_labels, test_labels = train_test_split(
        audio_paths, encoded_labels, test_size=0.3, random_state=42, stratify=encoded_labels
    )


    encoded_test_labels = label_encoder.fit_transform(test_labels)
    val_paths, test_paths, val_labels, test_labels = train_test_split(
      test_paths, test_labels, test_size=0.5, random_state=42, stratify=encoded_test_labels
    )

    train_labels = torch.tensor(train_labels).type(torch.LongTensor).to(device)
    test_labels = torch.tensor(test_labels).type(torch.LongTensor).to(device)
    val_labels = torch.tensor(val_labels).type(torch.LongTensor).to(device)

    #print(train_labels.dtype)


    # 4. Transformer les données en Dataset Hugging Face
    def preprocess_audio(audio_paths, labels):
        data = {'path': audio_paths, 'label': labels}
        dataset = Dataset.from_dict(data)
        return dataset

    train_dataset = preprocess_audio(train_paths, train_labels)
    test_dataset = preprocess_audio(test_paths, test_labels)
    val_dataset = preprocess_audio(val_paths, val_labels)

    # 5. Feature extractor et modèle HuBERT


    #model_path = "facebook/hubert-base-ls960"  # Or your local model path
    try:
      # Charger l'extracteur et le modèle HuBERT
      feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained("facebook/hubert-base-ls960")
      model = HubertForSequenceClassification.from_pretrained(
          "facebook/hubert-base-ls960",
          num_labels=len(classes)
      ).to(device)
      #model = HubertForSequenceClassification.from_pretrained(checkpoint_path)

      print("Model and processor loaded successfully.")
    except Exception as e:
        print(f"Error loading model: {e}")


    # 6. Prétraitement des fichiers audio

    def preprocess_function(examples):

      audio_arrays = [librosa.load(path, sr=16000)[0] for path in examples['path']]
      target_duration = 2  # 5 seconds
      sample_rate = 16000  # Échantillonnage en Hz
      target_size = target_duration * sample_rate  # Taille cible en échantillons

      # Ajuster la longueur de chaque signal audio
      audio_arrays = [
          librosa.util.fix_length(arr, size=target_size)
          for arr in audio_arrays
      ]

      inputs = feature_extractor(audio_arrays, sampling_rate=16000, padding=True, return_tensors="pt")
      # Transférer les entrées sur le bon appareil
      inputs = {key: tensor.to(device) for key, tensor in inputs.items()}
      inputs['labels'] = torch.tensor(examples['label']).type(torch.LongTensor).to(device)

      print(f"Train dataset label dtype: {inputs['labels'].dtype}")

      return inputs




    train_dataset = train_dataset.map(preprocess_function, batched=True)
    test_dataset = test_dataset.map(preprocess_function, batched=True)
    val_dataset = val_dataset.map(preprocess_function, batched=True)


    log_dir = 'logs'
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)

    # 7. Entraînement du modèle
    training_args = TrainingArguments(
      output_dir="./results",
      eval_strategy="epoch",
      logging_steps=10,
      learning_rate=1e-5, #5, 3, 1
      lr_scheduler_type="linear",  # linear or cosine Scheduler efficace pour ajuster le taux d'apprentissage
      warmup_steps=500,  # Étapes pour monter graduellement le taux d'apprentissage
      per_device_train_batch_size=8,
      per_device_eval_batch_size=8,
      num_train_epochs=12,
      save_total_limit=5,
      save_strategy="epoch",
      # resume_from_checkpoint=checkpoint_path,  # Charger à partir du checkpoint sauvegardé
      logging_dir="./logs",
      load_best_model_at_end=True,
      metric_for_best_model="accuracy",
      fp16=True,  # Utiliser le calcul en demi-précision pour accélérer l'entraînement (si votre GPU le supporte)
      gradient_accumulation_steps=2,
      greater_is_better=True,
      dataloader_num_workers=4,  # Nombre de workers pour le dataloader
    )


    from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, confusion_matrix

    from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, confusion_matrix
    from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, confusion_matrix
    import torch
    from sklearn.preprocessing import label_binarize
    import torch
    from torch.nn.functional import softmax



    global_labels = None
    global_predictions = None


    def compute_metrics(eval_pred):
        global global_labels, global_predictions

        logits, labels = eval_pred
        # Convertir logits en tensor et calculer les prédictions
        logits_tensor = torch.tensor(logits) if isinstance(logits, np.ndarray) else logits
        predictions = torch.argmax(logits_tensor, dim=-1)

        # Convertir labels en tensor
        labels_tensor = torch.tensor(labels) if isinstance(labels, np.ndarray) else labels

        # Calcul de l'accuracy
        accuracy = accuracy_score(labels_tensor.numpy(), predictions.numpy())

        # Calcul de la précision
        precision = precision_score(labels_tensor.numpy(), predictions.numpy(), average='weighted', zero_division=0)

        # Calcul du recall
        recall = recall_score(labels_tensor.numpy(), predictions.numpy(), average='weighted', zero_division=0)

        # Calcul du F-score
        fscore = f1_score(labels_tensor.numpy(), predictions.numpy(), average='weighted')

        # Calcul de l'AUC (Area Under Curve)
        labels_bin = label_binarize(labels_tensor.cpu(), classes=range(len(set(labels_tensor.cpu().numpy()))))
        predictions_bin = label_binarize(predictions.cpu(), classes=range(len(set(labels_tensor.cpu().numpy()))))
        auc = roc_auc_score(labels_bin, predictions_bin, average='weighted', multi_class='ovr')



        # Exemple de logits du modèle
        #probabilities = softmax(logits_tensor, dim=-1)

        # Convertir les labels et les prédictions en binaires
        #labels_bin = label_binarize(labels_tensor.cpu().numpy(), classes=range(len(set(labels_tensor.cpu().numpy()))))
        #predictions_bin = label_binarize(probabilities.cpu(), classes=range(len(set(labels_tensor.cpu().numpy())))) #probabilities.cpu().detach().numpy()

        # Calcul de l'AUC
        #auc = roc_auc_score(labels_bin, probabilities, average='weighted', multi_class='ovr')


        # Matrice de confusion multiclasse
        cm = confusion_matrix(labels_tensor.numpy(), predictions.numpy())

        # Initialisation des métriques
        sensitivities = []
        specificities = []

        for i in range(cm.shape[0]):
            TP = cm[i, i]  # Vrai positif pour la classe i
            FN = cm[i, :].sum() - TP  # Faux négatif pour la classe i
            FP = cm[:, i].sum() - TP  # Faux positif pour la classe i
            TN = cm.sum() - (TP + FP + FN)  # Vrai négatif pour la classe i

            # Sensibilité (Recall)
            sensitivity = TP / (TP + FN) if TP + FN > 0 else 0
            sensitivities.append(sensitivity)

            # Spécificité
            specificity = TN / (TN + FP) if TN + FP > 0 else 0
            specificities.append(specificity)

        # Moyenne des sensibilités et spécificités
        mean_sensitivity = np.mean(sensitivities)
        mean_specificity = np.mean(specificities)





        global_labels = labels_tensor.cpu()  # Stockage global des labels
        global_predictions = predictions.cpu()
        # Retourner les métriques sous forme de dictionnaire
        return {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': fscore,
            'auc': auc,
            'sensitivity': mean_sensitivity,
            'specificity': mean_specificity
        }



    # Ajouter EarlyStoppingCallback
    early_stopping_callback = EarlyStoppingCallback(early_stopping_patience=5)


    # Utiliser Trainer pour entraîner le modèle
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        processing_class=feature_extractor,
        #processing_class
        callbacks=[early_stopping_callback],  # Ajouter l'early stopping callback
        compute_metrics=compute_metrics
    )


    #print(f"Train dataset label dtype: {train_dataset[0]['labels'].dtype}")
    #print(f"Test dataset label dtype: {test_dataset[0]['labels'].dtype}")



    # Temps d'entraînement
    start_time = time.time()
    trainer.train()
    training_time = time.time() - start_time
    print(f"Temps d'entraînement : {training_time:.2f} secondes")

    # Évaluation
    results = trainer.evaluate()
    print(f"Résultats : {results}")

    # Temps d'inférence
    start_time = time.time()
    y_pred = np.argmax(trainer.predict(test_dataset).predictions, axis=1)
    inference_time = time.time() - start_time
    print(f"Temps d'evaluation : {inference_time:.2f} secondes")



    # Affichage de la matrice de confusion
    conf_matrix = confusion_matrix(test_dataset["label"], y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=label_encoder.classes_)
    disp.plot(cmap=plt.cm.Blues)
    plt.title("Matrice de Confusion")
    plt.show()





    def plot_roc_curve(labels, predictions, classes):
      # Convertir les labels et les prédictions en format binaire pour AUC (multi-classe)
      labels_bin = label_binarize(labels, classes=range(len(classes)))
      predictions_bin = label_binarize(predictions, classes=range(len(classes)))

      # Calculer la courbe ROC pour chaque classe
      fpr, tpr, _ = roc_curve(labels_bin.ravel(), predictions_bin.ravel())
      roc_auc = auc(fpr, tpr)

      # Afficher la courbe ROC
      plt.figure(figsize=(10, 6))
      plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')
      plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
      plt.xlim([0.0, 1.0])
      plt.ylim([0.0, 1.05])
      plt.xlabel('Taux de faux positifs (FPR)')
      plt.ylabel('Taux de vrais positifs (TPR)')
      plt.title('Courbe ROC (Receiver Operating Characteristic)')
      plt.legend(loc='lower right')
      plt.show()

    plot_roc_curve(global_labels, global_predictions, classes)

    def plot_loss_accuracy(history):
      # Extraire les données de l'historique
      train_loss = [entry['loss'] for entry in history if 'loss' in entry]
      eval_loss = [entry['eval_loss'] for entry in history if 'eval_loss' in entry]
      train_accuracy = [entry['accuracy'] for entry in history if 'accuracy' in entry]
      eval_accuracy = [entry['eval_accuracy'] for entry in history if 'eval_accuracy' in entry]

      # Tracer la courbe de perte
      plt.subplot(1, 2, 1)
      plt.plot(train_loss, label='Perte Entraînement', color='blue')
      plt.plot(eval_loss, label='Perte Validation', color='red')
      plt.title('Courbe de perte')
      plt.xlabel('Epochs')
      plt.ylabel('Perte')
      plt.legend()

      # Tracer la courbe de précision
      plt.subplot(1, 2, 2)
      plt.plot(train_accuracy, label='Précision Entraînement', color='blue')
      plt.plot(eval_accuracy, label='Précision Validation', color='red')
      plt.title('Courbe de précision')
      plt.xlabel('Epochs')
      plt.ylabel('Précision')
      plt.legend()

      plt.tight_layout()
      plt.show()

    # Appeler cette fonction avec l'historique de l'entraînement
    plot_loss_accuracy(trainer.state.log_history)



    # 9. Sauvegarder le modèle
    model.save_pretrained("models/hubert_note_classification")
    feature_extractor.save_pretrained("models/hubert_note_classification")
    print("Modèle et extractor sauvegardés sous 'hubert_note_classification'.")

import os
import torch
import librosa
import numpy as np
from datasets import Dataset
from transformers import EarlyStoppingCallback, Wav2Vec2Processor, Wav2Vec2ForSequenceClassification, TrainingArguments, Trainer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc


import time
import matplotlib.pyplot as plt
from sklearn.preprocessing import label_binarize

from google.colab import drive
drive.mount('/content/drive')

#dataset_root = '/content/drive/MyDrive/Dataset/guitar_dataset_test'
dataset_root = '/content/drive/MyDrive/Dataset/dataset_tests'


if __name__ == "__main__":

    # Vérifier la disponibilité de GPU
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Utilisation de l'appareil : {device}")

    # 1. Préparation des données
    def load_audio_files(dataset_root):

        data = []
        labels = []

        note_folders = [folder for folder in os.listdir(dataset_root) if os.path.isdir(os.path.join(dataset_root, folder))]

        for note_folder in note_folders:
            note_path = os.path.join(dataset_root, note_folder)
            wav_files = [f for f in os.listdir(note_path) if f.endswith('.wav')]

            for wav_file in wav_files:
                file_path = os.path.join(note_path, wav_file)
                data.append(file_path)
                labels.append(note_folder.upper())  # Utiliser le nom du dossier comme label

        return data, labels

    audio_paths, labels = load_audio_files(dataset_root)

    # 2. Encodage des labels
    label_encoder = LabelEncoder()
    encoded_labels = label_encoder.fit_transform(labels)

    # Sauvegarder les classes pour référence future
    classes = label_encoder.classes_
    print(f"Classes détectées : {classes}")

    # 3. Séparer en ensembles d'entraînement et de test
    train_paths, test_paths, train_labels, test_labels = train_test_split(
        audio_paths, encoded_labels, test_size=0.3, random_state=42, stratify=encoded_labels
    )


    encoded_test_labels = label_encoder.fit_transform(test_labels)
    val_paths, test_paths, val_labels, test_labels = train_test_split(
      test_paths, test_labels, test_size=0.5, random_state=42, stratify=encoded_test_labels
    )

    train_labels = torch.tensor(train_labels).type(torch.LongTensor).to(device)
    test_labels = torch.tensor(test_labels).type(torch.LongTensor).to(device)
    val_labels = torch.tensor(val_labels).type(torch.LongTensor).to(device)


    # 4. Transformer les données en Dataset Hugging Face
    def preprocess_audio(audio_paths, labels):
        data = {'path': audio_paths, 'label': labels}
        dataset = Dataset.from_dict(data)
        return dataset

    train_dataset = preprocess_audio(train_paths, train_labels)
    test_dataset = preprocess_audio(test_paths, test_labels)
    val_dataset = preprocess_audio(val_paths, val_labels)

    # 5. Feature extractor et modèle Wav2Vec2


    try:
        # Charger l'extracteur et le modèle Wav2Vec2
        processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base-960h")
        model = Wav2Vec2ForSequenceClassification.from_pretrained(
            "facebook/wav2vec2-base-960h",
            num_labels=len(classes)
        ).to(device)

        print("Model and processor loaded successfully.")
    except Exception as e:
        print(f"Error loading model: {e}")


    # 6. Prétraitement des fichiers audio

    def preprocess_function(examples):
      audio_arrays = [librosa.load(path, sr=16000)[0] for path in examples['path']]
      inputs = processor(audio_arrays, sampling_rate=16000, padding=True, return_tensors="pt")
      # Transférer les entrées sur le bon appareil
      inputs = {key: tensor.to(device) for key, tensor in inputs.items()}
      inputs['labels'] = torch.tensor(examples['label']).type(torch.LongTensor).to(device)

      print(f"Train dataset label dtype: {inputs['labels'].dtype}")

      return inputs


    train_dataset = train_dataset.map(preprocess_function, batched=True)
    test_dataset = test_dataset.map(preprocess_function, batched=True)
    val_dataset = val_dataset.map(preprocess_function, batched=True)


    log_dir = 'logs'
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)

    # 7. Entraînement du modèle
    training_args = TrainingArguments(
      output_dir="./results",
      eval_strategy="epoch",
      logging_steps=10,
      learning_rate=5e-5, #5, 3, 1
      lr_scheduler_type="linear",  # linear or cosine Scheduler efficace pour ajuster le taux d'apprentissage
      warmup_steps=500,  # Étapes pour monter graduellement le taux d'apprentissage
      per_device_train_batch_size=8,
      per_device_eval_batch_size=16,
      num_train_epochs=10,
      save_total_limit=5,
      save_strategy="epoch",
      logging_dir="./logs",

      load_best_model_at_end=True,
      metric_for_best_model="accuracy",
      fp16=True,  # Utiliser le calcul en demi-précision pour accélérer l'entraînement (si votre GPU le supporte)
      gradient_accumulation_steps=2,
      greater_is_better=True,
      dataloader_num_workers=4,  # Nombre de workers pour le dataloader
    )


    global_labels = None
    global_predictions = None


    def compute_metrics(eval_pred):
        global global_labels, global_predictions

        logits, labels = eval_pred
        # Convertir logits en tensor et calculer les prédictions
        logits_tensor = torch.tensor(logits) if isinstance(logits, np.ndarray) else logits
        predictions = torch.argmax(logits_tensor, dim=-1)

        # Convertir labels en tensor
        labels_tensor = torch.tensor(labels) if isinstance(labels, np.ndarray) else labels

        # Calcul de l'accuracy
        accuracy = accuracy_score(labels_tensor.cpu(), predictions.cpu())

        # Calcul de la précision
        precision = precision_score(labels_tensor.cpu(), predictions.cpu(), average='weighted', zero_division=0)

        # Calcul du recall
        recall = recall_score(labels_tensor.cpu(), predictions.cpu(), average='weighted', zero_division=0)

        # Calcul du F-score
        fscore = f1_score(labels_tensor.cpu(), predictions.cpu(), average='weighted')

        # Calcul de l'AUC (Area Under Curve)
        labels_bin = label_binarize(labels_tensor.cpu(), classes=range(len(set(labels_tensor.cpu().numpy()))))
        predictions_bin = label_binarize(predictions.cpu(), classes=range(len(set(labels_tensor.cpu().numpy()))))
        auc = roc_auc_score(labels_bin, predictions_bin, average='weighted', multi_class='ovr')


        # Calcul des métriques par classe
        cm = confusion_matrix(labels_tensor.cpu(), predictions.cpu())
        class_counts = np.bincount(labels_tensor.cpu().numpy())
        specificity_per_class = []
        for i in range(len(cm)):
            TN = cm.sum() - cm[i, :].sum() - cm[:, i].sum() + cm[i, i]
            FP = cm[:, i].sum() - cm[i, i]
            specificity = TN / (TN + FP) if (TN + FP) > 0 else 0
            specificity_per_class.append(specificity)
        weighted_specificity = np.average(specificity_per_class, weights=class_counts)


        global_labels = labels_tensor.cpu()  # Stockage global des labels
        global_predictions = predictions.cpu()
        # Retourner les métriques sous forme de dictionnaire
        return {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': fscore,
            'auc': auc,
            'sensitivity': recall,
            'specificity': weighted_specificity
        }


    # Utiliser Trainer pour entraîner le modèle
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        processing_class=processor,
        compute_metrics=compute_metrics
    )


    # Temps d'entraînement
    start_time = time.time()
    trainer.train()
    training_time = time.time() - start_time
    print(f"Temps d'entraînement : {training_time:.2f} secondes")

    # Évaluation
    results = trainer.evaluate()
    print(f"Résultats : {results}")

    # Temps d'inférence
    start_time = time.time()
    y_pred = np.argmax(trainer.predict(test_dataset).predictions, axis=1)
    inference_time = time.time() - start_time
    print(f"Temps d'evaluation : {inference_time:.2f} secondes")


    # Affichage de la matrice de confusion
    conf_matrix = confusion_matrix(test_dataset["label"], y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=label_encoder.classes_)
    disp.plot(cmap=plt.cm.Blues)
    plt.title("Matrice de Confusion")
    plt.show()


    def plot_roc_curve(labels, predictions, classes):
      labels_bin = label_binarize(labels, classes=range(len(classes)))
      predictions_bin = label_binarize(predictions, classes=range(len(classes)))

      fpr, tpr, _ = roc_curve(labels_bin.ravel(), predictions_bin.ravel())
      roc_auc = auc(fpr, tpr)

      plt.figure(figsize=(10, 6))
      plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')
      plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
      plt.xlim([0.0, 1.0])
      plt.ylim([0.0, 1.05])
      plt.xlabel('Taux de faux positifs (FPR)')
      plt.ylabel('Taux de vrais positifs (TPR)')
      plt.title('Courbe ROC (Receiver Operating Characteristic)')
      plt.legend(loc='lower right')
      plt.show()

    plot_roc_curve(global_labels, global_predictions, classes)

    def plot_loss_accuracy(history):
      train_loss = [entry['loss'] for entry in history if 'loss' in entry]
      eval_loss = [entry['eval_loss'] for entry in history if 'eval_loss' in entry]
      train_accuracy = [entry['accuracy'] for entry in history if 'accuracy' in entry]
      eval_accuracy = [entry['eval_accuracy'] for entry in history if 'eval_accuracy' in entry]

      plt.subplot(1, 2, 1)
      plt.plot(train_loss, label='Perte Entraînement', color='blue')
      plt.plot(eval_loss, label='Perte Validation', color='red')
      plt.title('Courbe de perte')
      plt.xlabel('Epochs')
      plt.ylabel('Perte')
      plt.legend()

      plt.subplot(1, 2, 2)
      plt.plot(train_accuracy, label='Précision Entraînement', color='blue')
      plt.plot(eval_accuracy, label='Précision Validation', color='red')
      plt.title('Courbe de précision')
      plt.xlabel('Epochs')
      plt.ylabel('Précision')
      plt.legend()

      plt.tight_layout()
      plt.show()

    plot_loss_accuracy(trainer.state.log_history)

    # Sauvegarder le modèle
    model.save_pretrained("models/wav2vec2_note_classification")
    processor.save_pretrained("models/wav2vec2_note_classification")
    print("Modèle et processor sauvegardés sous 'wav2vec2_note_classification'.")

import os
import torch
import librosa
import numpy as np
from datasets import Dataset
from transformers import EarlyStoppingCallback, Wav2Vec2FeatureExtractor, TrainingArguments, Trainer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, label_binarize
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
import time
import matplotlib.pyplot as plt
from google.colab import drive

drive.mount('/content/drive')

# Dataset path
dataset_root = '/content/drive/MyDrive/Dataset/dataset_sample'
dataset_root = '/content/drive/MyDrive/Dataset/dataset_tests'

# Vérification de la disponibilité du GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Utilisation de l'appareil : {device}")

# Chargement des fichiers audio et des labels
def load_audio_files(dataset_root):
    data = []
    labels = []
    note_folders = [folder for folder in os.listdir(dataset_root) if os.path.isdir(os.path.join(dataset_root, folder))]
    for note_folder in note_folders:
        note_path = os.path.join(dataset_root, note_folder)
        wav_files = [f for f in os.listdir(note_path) if f.endswith('.wav')]
        for wav_file in wav_files:
            file_path = os.path.join(note_path, wav_file)
            data.append(file_path)
            labels.append(note_folder.upper())  # Utiliser le nom du dossier comme label
    return data, labels

audio_paths, labels = load_audio_files(dataset_root)

# Encodage des labels
label_encoder = LabelEncoder()
encoded_labels = label_encoder.fit_transform(labels)
classes = label_encoder.classes_
print(f"Classes détectées : {classes}")

# Séparer les ensembles de données
train_paths, test_paths, train_labels, test_labels = train_test_split(
    audio_paths, encoded_labels, test_size=0.3, random_state=42, stratify=encoded_labels
)
val_paths, test_paths, val_labels, test_labels = train_test_split(
    test_paths, test_labels, test_size=0.5, random_state=42, stratify=test_labels
)

# Préparer les datasets Hugging Face
def preprocess_audio(audio_paths, labels):
    data = {'path': audio_paths, 'label': [int(label) for label in labels]}
    dataset = Dataset.from_dict(data)
    return dataset

train_dataset = preprocess_audio(train_paths, train_labels)
test_dataset = preprocess_audio(test_paths, test_labels)
val_dataset = preprocess_audio(val_paths, val_labels)

# Charger l'extracteur et le modèle AST
from transformers import AutoFeatureExtractor, ASTForAudioClassification

feature_extractor = AutoFeatureExtractor.from_pretrained("MIT/ast-finetuned-audioset-10-10-0.4593")
model = ASTForAudioClassification.from_pretrained("MIT/ast-finetuned-audioset-10-10-0.4593").to(device)
#model = ASTForAudioClassification.from_pretrained("checkpoint-4").to(device)

# Prétraitement des fichiers audio
def preprocess_function(examples):
    audio_arrays = [librosa.load(path, sr=16000)[0] for path in examples['path']]
    target_duration = 2  # 2 secondes
    sample_rate = 16000
    target_size = target_duration * sample_rate
    audio_arrays = [librosa.util.fix_length(arr, size=target_size) for arr in audio_arrays]
    inputs = feature_extractor(audio_arrays, sampling_rate=16000, padding=True, return_tensors="pt")
    inputs = {key: tensor.to(device) for key, tensor in inputs.items()}
    inputs['labels'] = torch.tensor(examples['label']).to(device)
    return inputs

train_dataset = train_dataset.map(preprocess_function, batched=True, remove_columns=["path", "label"])
test_dataset = test_dataset.map(preprocess_function, batched=True, remove_columns=["path", "label"])
val_dataset = val_dataset.map(preprocess_function, batched=True, remove_columns=["path", "label"])

# Arguments d'entraînement
training_args = TrainingArguments(
    output_dir="./results",
    eval_strategy="epoch",
    logging_steps=10,
    learning_rate=2e-5,
    lr_scheduler_type="linear",
    warmup_steps=500,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=10,
    save_total_limit=5,
    save_strategy="epoch",
    logging_dir="./logs",
    load_best_model_at_end=True,
    metric_for_best_model="accuracy",
    fp16=True,
    gradient_accumulation_steps=2,
    greater_is_better=True,
    dataloader_num_workers=4,
)
global_labels = None
global_predictions = None

# Fonction de calcul des métriques
def compute_metrics(eval_pred):
        global global_labels, global_predictions

        logits, labels = eval_pred
        # Convertir logits en tensor et calculer les prédictions
        logits_tensor = torch.tensor(logits) if isinstance(logits, np.ndarray) else logits
        predictions = torch.argmax(logits_tensor, dim=-1)

        # Convertir labels en tensor
        labels_tensor = torch.tensor(labels) if isinstance(labels, np.ndarray) else labels

        # Calcul de l'accuracy
        accuracy = accuracy_score(labels_tensor.cpu(), predictions.cpu())

        # Calcul de la précision
        precision = precision_score(labels_tensor.cpu(), predictions.cpu(), average='weighted', zero_division=0)

        # Calcul du recall
        recall = recall_score(labels_tensor.cpu(), predictions.cpu(), average='weighted', zero_division=0)

        # Calcul du F-score
        fscore = f1_score(labels_tensor.cpu(), predictions.cpu(), average='weighted')

        # Calcul de l'AUC (Area Under Curve)
        labels_bin = label_binarize(labels_tensor.cpu(), classes=range(len(set(labels_tensor.cpu().numpy()))))
        predictions_bin = label_binarize(predictions.cpu(), classes=range(len(set(labels_tensor.cpu().numpy()))))
        auc = roc_auc_score(labels_bin, predictions_bin, average='weighted', multi_class='ovr')


        # Calcul des métriques par classe
        cm = confusion_matrix(labels_tensor.cpu(), predictions.cpu())
        # Extraction des éléments de la matrice de confusion
        TN = cm[0, 0]  # Vrai négatif
        FP = cm[0, 1]  # Faux positif
        FN = cm[1, 0]  # Faux négatif
        TP = cm[1, 1]  # Vrai positif

        # Calcul de la spécificité
        specificity = TN / (TN + FP) if (TN + FP) > 0 else 0

        # Calcul de la sensibilité (facultatif)
        sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0

        global_labels = labels_tensor.cpu()  # Stockage global des labels
        global_predictions = predictions.cpu()
        # Retourner les métriques sous forme de dictionnaire
        return {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': fscore,
            'auc': auc,
            'sensitivity': specificity,
            'specificity': sensitivity
        }


# Entraînement du modèle
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    processing_class=feature_extractor,
    compute_metrics=compute_metrics,
)

start_time = time.time()
trainer.train()
training_time = time.time() - start_time
print(f"Temps d'entraînement : {training_time:.2f} secondes")

# Évaluation finale
results = trainer.evaluate()
print(f"Résultats : {results}")

# Sauvegarde du modèle
model.save_pretrained("models/ast_note_classification")
feature_extractor.save_pretrained("models/ast_note_classification")
print("Modèle et extractor sauvegardés sous 'ast_note_classification'.")

import os
import torch
import librosa
import numpy as np
from datasets import Dataset
from transformers import EarlyStoppingCallback, Wav2Vec2Processor, Wav2Vec2ForCTC, TrainingArguments, Trainer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc


import time
import matplotlib.pyplot as plt
from sklearn.preprocessing import label_binarize

from google.colab import drive
drive.mount('/content/drive')

#dataset_root = '/content/drive/MyDrive/Dataset/guitar_dataset_test'
dataset_root = '/content/drive/MyDrive/Dataset/dataset_tests'


if __name__ == "__main__":

    # Vérifier la disponibilité de GPU
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Utilisation de l'appareil : {device}")

    # 1. Préparation des données
    def load_audio_files(dataset_root):

        data = []
        labels = []

        note_folders = [folder for folder in os.listdir(dataset_root) if os.path.isdir(os.path.join(dataset_root, folder))]

        for note_folder in note_folders:
            note_path = os.path.join(dataset_root, note_folder)
            wav_files = [f for f in os.listdir(note_path) if f.endswith('.wav')]

            for wav_file in wav_files:
                file_path = os.path.join(note_path, wav_file)
                data.append(file_path)
                labels.append(note_folder.upper())  # Utiliser le nom du dossier comme label

        return data, labels

    audio_paths, labels = load_audio_files(dataset_root)

    # 2. Encodage des labels
    label_encoder = LabelEncoder()
    encoded_labels = label_encoder.fit_transform(labels)

    # Sauvegarder les classes pour référence future
    classes = label_encoder.classes_
    print(f"Classes détectées : {classes}")

    # 3. Séparer en ensembles d'entraînement et de test
    train_paths, test_paths, train_labels, test_labels = train_test_split(
        audio_paths, encoded_labels, test_size=0.3, random_state=42, stratify=encoded_labels
    )

    encoded_test_labels = label_encoder.fit_transform(test_labels)
    val_paths, test_paths, val_labels, test_labels = train_test_split(
      test_paths, test_labels, test_size=0.5, random_state=42, stratify=encoded_test_labels
    )

    train_labels = torch.tensor(train_labels).type(torch.LongTensor).to(device)
    test_labels = torch.tensor(test_labels).type(torch.LongTensor).to(device)
    val_labels = torch.tensor(val_labels).type(torch.LongTensor).to(device)


    # 4. Transformer les données en Dataset Hugging Face
    def preprocess_audio(audio_paths, labels):
        data = {'path': audio_paths, 'label': labels}
        dataset = Dataset.from_dict(data)
        return dataset

    train_dataset = preprocess_audio(train_paths, train_labels)
    test_dataset = preprocess_audio(test_paths, test_labels)
    val_dataset = preprocess_audio(val_paths, val_labels)

    # 5. Feature extractor et modèle Wav2Vec2

    try:
        # Charger l'extracteur et le modèle Wav2Vec2
        processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base-960h")
        from transformers import Wav2Vec2ForSequenceClassification

          # Charger le modèle pour la classification
        model = Wav2Vec2ForSequenceClassification.from_pretrained(
              "facebook/wav2vec2-base-960h", num_labels=len(classes)
          ).to(device)


        # Ajouter une couche de classification après l'encodeur
        model.classifier = torch.nn.Linear(256, len(classes))  # 256 doit correspondre à la sortie de votre modèle
        model.to(device)


        print("Modèle Wav2Vec2 chargé et ajusté pour la classification.")
    except Exception as e:
        print(f"Erreur lors du chargement du modèle: {e}")

    # 6. Prétraitement des fichiers audio

    def preprocess_function(examples):
      # Charger les fichiers audio et prétraiter
      audio_arrays = [librosa.load(path, sr=16000)[0] for path in examples['path']]
      inputs = processor(audio_arrays, sampling_rate=16000, padding=True, return_tensors="pt")

      # Transférer les entrées sur le bon appareil
      inputs = {key: tensor.to(device) for key, tensor in inputs.items()}

      # Ajouter les labels
      inputs['labels'] = torch.tensor(examples['label']).type(torch.LongTensor).to(device)

      return inputs




    train_dataset = train_dataset.map(preprocess_function, batched=True)
    test_dataset = test_dataset.map(preprocess_function, batched=True)
    val_dataset = val_dataset.map(preprocess_function, batched=True)


    log_dir = 'logs'
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)

    # 7. Entraînement du modèle
    training_args = TrainingArguments(
      output_dir="./results",
      eval_strategy="epoch",
      logging_steps=10,
      learning_rate=5e-5, #5, 3, 1
      lr_scheduler_type="linear",  # linear ou cosine Scheduler efficace pour ajuster le taux d'apprentissage
      warmup_steps=500,  # Étapes pour monter graduellement le taux d'apprentissage
      per_device_train_batch_size=8,
      per_device_eval_batch_size=16,
      num_train_epochs=10,
      save_total_limit=5,
      save_strategy="epoch",
      logging_dir="./logs",

      load_best_model_at_end=True,
      metric_for_best_model="accuracy",
      fp16=True,  # Utiliser le calcul en demi-précision pour accélérer l'entraînement (si votre GPU le supporte)
      gradient_accumulation_steps=2,
      greater_is_better=True,
      dataloader_num_workers=4,  # Nombre de workers pour le dataloader
    )


    global_labels = None
    global_predictions = None


    def compute_metrics(eval_pred):
        global global_labels, global_predictions

        logits, labels = eval_pred
        # Convertir logits en tensor et calculer les prédictions
        logits_tensor = torch.tensor(logits) if isinstance(logits, np.ndarray) else logits
        predictions = torch.argmax(logits_tensor, dim=-1)

        # Convertir labels en tensor
        labels_tensor = torch.tensor(labels) if isinstance(labels, np.ndarray) else labels

        # Calcul de l'accuracy
        accuracy = accuracy_score(labels_tensor.cpu(), predictions.cpu())

        # Calcul de la précision
        precision = precision_score(labels_tensor.cpu(), predictions.cpu(), average='weighted', zero_division=0)

        # Calcul du recall
        recall = recall_score(labels_tensor.cpu(), predictions.cpu(), average='weighted', zero_division=0)

        # Calcul du F-score
        fscore = f1_score(labels_tensor.cpu(), predictions.cpu(), average='weighted')

        # Calcul de l'AUC (Area Under Curve)
        labels_bin = label_binarize(labels_tensor.cpu(), classes=range(len(set(labels_tensor.cpu().numpy()))))
        predictions_bin = label_binarize(predictions.cpu(), classes=range(len(set(labels_tensor.cpu().numpy()))))
        auc = roc_auc_score(labels_bin, predictions_bin, average='weighted', multi_class='ovr')


        # Calcul des métriques par classe
        cm = confusion_matrix(labels_tensor.cpu(), predictions.cpu())
        class_counts = np.bincount(labels_tensor.cpu().numpy())
        specificity_per_class = []
        for i in range(len(cm)):
            TN = cm.sum() - cm[i, :].sum() - cm[:, i].sum() + cm[i, i]
            FP = cm[:, i].sum() - cm[i, i]
            specificity = TN / (TN + FP) if (TN + FP) > 0 else 0
            specificity_per_class.append(specificity)
        weighted_specificity = np.average(specificity_per_class, weights=class_counts)


        global_labels = labels_tensor.cpu()  # Stockage global des labels
        global_predictions = predictions.cpu()
        # Retourner les métriques sous forme de dictionnaire
        return {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': fscore,
            'auc': auc,
            'sensitivity': recall,
            'specificity': weighted_specificity
        }


    # Utiliser Trainer pour entraîner le modèle
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        processing_class=processor,
        compute_metrics=compute_metrics
    )


    # Temps d'entraînement
    start_time = time.time()
    trainer.train()
    training_time = time.time() - start_time
    print(f"Temps d'entraînement : {training_time:.2f} secondes")

    # Évaluation
    results = trainer.evaluate()
    print(f"Résultats : {results}")

    # Temps d'inférence
    start_time = time.time()
    y_pred = np.argmax(trainer.predict(test_dataset).predictions, axis=1)
    inference_time = time.time() - start_time
    print(f"Temps d'evaluation : {inference_time:.2f} secondes")


    # Affichage de la matrice de confusion
    conf_matrix = confusion_matrix(test_dataset["label"], y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=label_encoder.classes_)
    disp.plot(cmap=plt.cm.Blues)
    plt.title("Matrice de Confusion")
    plt.show()


    def plot_roc_curve(labels, predictions, classes):
      labels_bin = label_binarize(labels, classes=range(len(classes)))
      predictions_bin = label_binarize(predictions, classes=range(len(classes)))

      fpr, tpr, _ = roc_curve(labels_bin.ravel(), predictions_bin.ravel())
      roc_auc = auc(fpr, tpr)

      plt.figure(figsize=(10, 6))
      plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')
      plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
      plt.xlim([0.0, 1.0])
      plt.ylim([0.0, 1.05])
      plt.xlabel('Taux de faux positifs (FPR)')
      plt.ylabel('Taux de vrais positifs (TPR)')
      plt.title('Courbe ROC (Receiver Operating Characteristic)')
      plt.legend(loc='lower right')
      plt.show()

    plot_roc_curve(global_labels, global_predictions, classes)

    def plot_loss_accuracy(history):
      train_loss = [entry['loss'] for entry in history if 'loss' in entry]
      eval_loss = [entry['eval_loss'] for entry in history if 'eval_loss' in entry]
      train_accuracy = [entry['accuracy'] for entry in history if 'accuracy' in entry]
      eval_accuracy = [entry['eval_accuracy'] for entry in history if 'eval_accuracy' in entry]

      plt.subplot(1, 2, 1)
      plt.plot(train_loss, label="Loss d'entraînement")
      plt.plot(eval_loss, label="Loss de validation")
      plt.title('Courbes de perte')
      plt.legend()

      plt.subplot(1, 2, 2)
      plt.plot(train_accuracy, label="Accuracy d'entraînement")
      plt.plot(eval_accuracy, label="Accuracy de validation")
      plt.title('Courbes de précision')
      plt.legend()

      plt.tight_layout()
      plt.show()

    plot_loss_accuracy(trainer.state.log_history)


# 11. Sauvegarde du modèle
model.save_pretrained("models/wav2vec_note_classification")
feature_extractor.save_pretrained("models/wav2vec_note_classification")
print("Modèle et extracteur sauvegardés.")

import os
import torch
import librosa
import numpy as np
from datasets import Dataset
from transformers import EarlyStoppingCallback, Wav2Vec2FeatureExtractor, HubertForSequenceClassification, ViTForImageClassification, ViTFeatureExtractor, TrainingArguments, Trainer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc


import time
import matplotlib.pyplot as plt
from sklearn.preprocessing import label_binarize


from google.colab import drive
drive.mount('/content/drive')

#dataset_root = '/content/drive/MyDrive/Dataset/guitar_dataset_test'
#dataset_root = '/content/drive/MyDrive/Dataset/dataset_tests'
#dataset_root = '/content/drive/MyDrive/Dataset/guitar_dataset'
dataset_root = '/content/drive/MyDrive/Dataset/dataset_sample'




import logging
logging.basicConfig(level=logging.INFO, force=True)




if __name__ == "__main__":
    # Définir le chemin de la racine de votre dataset
    #dataset_root = 'dataset/guitar dataset'
    #dataset_root = 'dataset/guitar_dataset_test'



    # Vérifier la disponibilité de GPU
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Utilisation de l'appareil : {device}")

    # 1. Préparation des données
    def load_audio_files(dataset_root):

        data = []
        labels = []

        note_folders = [folder for folder in os.listdir(dataset_root) if os.path.isdir(os.path.join(dataset_root, folder))]

        for note_folder in note_folders:
            note_path = os.path.join(dataset_root, note_folder)
            wav_files = [f for f in os.listdir(note_path) if f.endswith('.wav')]

            for wav_file in wav_files:
                file_path = os.path.join(note_path, wav_file)
                data.append(file_path)
                labels.append(note_folder.upper())  # Utiliser le nom du dossier comme label

        return data, labels

    audio_paths, labels = load_audio_files(dataset_root)

    # 2. Encodage des labels
    label_encoder = LabelEncoder()
    encoded_labels = label_encoder.fit_transform(labels)

    # Sauvegarder les classes pour référence future
    classes = label_encoder.classes_
    print(f"Classes détectées : {classes}")

    # 3. Séparer en ensembles d'entraînement et de test
    train_paths, test_paths, train_labels, test_labels = train_test_split(
        audio_paths, encoded_labels, test_size=0.3, random_state=42, stratify=encoded_labels
    )


    encoded_test_labels = label_encoder.fit_transform(test_labels)
    val_paths, test_paths, val_labels, test_labels = train_test_split(
      test_paths, test_labels, test_size=0.5, random_state=42, stratify=encoded_test_labels
    )

    train_labels = torch.tensor(train_labels).type(torch.LongTensor).to(device)
    test_labels = torch.tensor(test_labels).type(torch.LongTensor).to(device)
    val_labels = torch.tensor(val_labels).type(torch.LongTensor).to(device)

    #print(train_labels.dtype)


    # 4. Transformer les données en Dataset Hugging Face
    def preprocess_audio(audio_paths, labels):
        data = {'path': audio_paths, 'label': labels}
        dataset = Dataset.from_dict(data)
        return dataset

    train_dataset = preprocess_audio(train_paths, train_labels)
    test_dataset = preprocess_audio(test_paths, test_labels)
    val_dataset = preprocess_audio(val_paths, val_labels)

    # 5. Feature extractor et modèle VIT


    try:
      # Charger l'extracteur et le modèle vİT

      feature_extractor = ViTFeatureExtractor.from_pretrained("google/vit-base-patch16-224")
      model = ViTForImageClassification.from_pretrained("google/vit-base-patch16-224", num_labels=10).to(device)
      #model = HubertForSequenceClassification.from_pretrained(checkpoint_path)

      print("Model and processor loaded successfully.")
    except Exception as e:
        print(f"Error loading model: {e}")


    # 6. Prétraitement des fichiers audio

    def preprocess_function(examples):

      audio_arrays = [librosa.load(path, sr=16000)[0] for path in examples['path']]
      target_duration = 2  # 5 seconds
      sample_rate = 16000  # Échantillonnage en Hz
      target_size = target_duration * sample_rate  # Taille cible en échantillons

      # Ajuster la longueur de chaque signal audio
      audio_arrays = [
          librosa.util.fix_length(arr, size=target_size)
          for arr in audio_arrays
      ]

      inputs = feature_extractor(audio_arrays, sampling_rate=16000, padding=True, return_tensors="pt")
      # Transférer les entrées sur le bon appareil
      inputs = {key: tensor.to(device) for key, tensor in inputs.items()}
      inputs['labels'] = torch.tensor(examples['label']).type(torch.LongTensor).to(device)

      print(f"Train dataset label dtype: {inputs['labels'].dtype}")

      return inputs




    train_dataset = train_dataset.map(preprocess_function, batched=True)
    test_dataset = test_dataset.map(preprocess_function, batched=True)
    val_dataset = val_dataset.map(preprocess_function, batched=True)


    log_dir = 'logs'
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)

    # 7. Entraînement du modèle
    training_args = TrainingArguments(
      output_dir="./results",
      eval_strategy="epoch",
      logging_steps=10,
      learning_rate=1e-5, #5, 3, 1
      lr_scheduler_type="linear",  # linear or cosine Scheduler efficace pour ajuster le taux d'apprentissage
      warmup_steps=500,  # Étapes pour monter graduellement le taux d'apprentissage
      per_device_train_batch_size=8,
      per_device_eval_batch_size=8,
      num_train_epochs=12,
      save_total_limit=5,
      save_strategy="epoch",
      # resume_from_checkpoint=checkpoint_path,  # Charger à partir du checkpoint sauvegardé
      logging_dir="./logs",
      load_best_model_at_end=True,
      metric_for_best_model="accuracy",
      fp16=True,  # Utiliser le calcul en demi-précision pour accélérer l'entraînement (si votre GPU le supporte)
      gradient_accumulation_steps=2,
      greater_is_better=True,
      dataloader_num_workers=4,  # Nombre de workers pour le dataloader
    )


    from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, confusion_matrix

    from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, confusion_matrix
    from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, confusion_matrix
    import torch
    from sklearn.preprocessing import label_binarize
    import torch
    from torch.nn.functional import softmax



    global_labels = None
    global_predictions = None


    def compute_metrics(eval_pred):
        global global_labels, global_predictions

        logits, labels = eval_pred
        # Convertir logits en tensor et calculer les prédictions
        logits_tensor = torch.tensor(logits) if isinstance(logits, np.ndarray) else logits
        predictions = torch.argmax(logits_tensor, dim=-1)

        # Convertir labels en tensor
        labels_tensor = torch.tensor(labels) if isinstance(labels, np.ndarray) else labels

        # Calcul de l'accuracy
        accuracy = accuracy_score(labels_tensor.numpy(), predictions.numpy())

        # Calcul de la précision
        precision = precision_score(labels_tensor.numpy(), predictions.numpy(), average='weighted', zero_division=0)

        # Calcul du recall
        recall = recall_score(labels_tensor.numpy(), predictions.numpy(), average='weighted', zero_division=0)

        # Calcul du F-score
        fscore = f1_score(labels_tensor.numpy(), predictions.numpy(), average='weighted')

        # Calcul de l'AUC (Area Under Curve)
        labels_bin = label_binarize(labels_tensor.cpu(), classes=range(len(set(labels_tensor.cpu().numpy()))))
        predictions_bin = label_binarize(predictions.cpu(), classes=range(len(set(labels_tensor.cpu().numpy()))))
        auc = roc_auc_score(labels_bin, predictions_bin, average='weighted', multi_class='ovr')



        # Exemple de logits du modèle
        #probabilities = softmax(logits_tensor, dim=-1)

        # Convertir les labels et les prédictions en binaires
        #labels_bin = label_binarize(labels_tensor.cpu().numpy(), classes=range(len(set(labels_tensor.cpu().numpy()))))
        #predictions_bin = label_binarize(probabilities.cpu(), classes=range(len(set(labels_tensor.cpu().numpy())))) #probabilities.cpu().detach().numpy()

        # Calcul de l'AUC
        #auc = roc_auc_score(labels_bin, probabilities, average='weighted', multi_class='ovr')


        # Matrice de confusion multiclasse
        cm = confusion_matrix(labels_tensor.numpy(), predictions.numpy())

        # Initialisation des métriques
        sensitivities = []
        specificities = []

        for i in range(cm.shape[0]):
            TP = cm[i, i]  # Vrai positif pour la classe i
            FN = cm[i, :].sum() - TP  # Faux négatif pour la classe i
            FP = cm[:, i].sum() - TP  # Faux positif pour la classe i
            TN = cm.sum() - (TP + FP + FN)  # Vrai négatif pour la classe i

            # Sensibilité (Recall)
            sensitivity = TP / (TP + FN) if TP + FN > 0 else 0
            sensitivities.append(sensitivity)

            # Spécificité
            specificity = TN / (TN + FP) if TN + FP > 0 else 0
            specificities.append(specificity)

        # Moyenne des sensibilités et spécificités
        mean_sensitivity = np.mean(sensitivities)
        mean_specificity = np.mean(specificities)





        global_labels = labels_tensor.cpu()  # Stockage global des labels
        global_predictions = predictions.cpu()
        # Retourner les métriques sous forme de dictionnaire
        return {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': fscore,
            'auc': auc,
            'sensitivity': mean_sensitivity,
            'specificity': mean_specificity
        }



    # Ajouter EarlyStoppingCallback
    early_stopping_callback = EarlyStoppingCallback(early_stopping_patience=5)


    # Utiliser Trainer pour entraîner le modèle
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        processing_class=feature_extractor,
        #processing_class
        callbacks=[early_stopping_callback],  # Ajouter l'early stopping callback
        compute_metrics=compute_metrics
    )


    #print(f"Train dataset label dtype: {train_dataset[0]['labels'].dtype}")
    #print(f"Test dataset label dtype: {test_dataset[0]['labels'].dtype}")



    # Temps d'entraînement
    start_time = time.time()
    trainer.train()
    training_time = time.time() - start_time
    print(f"Temps d'entraînement : {training_time:.2f} secondes")

    # Évaluation
    results = trainer.evaluate()
    print(f"Résultats : {results}")

    # Temps d'inférence
    start_time = time.time()
    y_pred = np.argmax(trainer.predict(test_dataset).predictions, axis=1)
    inference_time = time.time() - start_time
    print(f"Temps d'evaluation : {inference_time:.2f} secondes")



    # Affichage de la matrice de confusion
    conf_matrix = confusion_matrix(test_dataset["label"], y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=label_encoder.classes_)
    disp.plot(cmap=plt.cm.Blues)
    plt.title("Matrice de Confusion")
    plt.show()





    def plot_roc_curve(labels, predictions, classes):
      # Convertir les labels et les prédictions en format binaire pour AUC (multi-classe)
      labels_bin = label_binarize(labels, classes=range(len(classes)))
      predictions_bin = label_binarize(predictions, classes=range(len(classes)))

      # Calculer la courbe ROC pour chaque classe
      fpr, tpr, _ = roc_curve(labels_bin.ravel(), predictions_bin.ravel())
      roc_auc = auc(fpr, tpr)

      # Afficher la courbe ROC
      plt.figure(figsize=(10, 6))
      plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')
      plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
      plt.xlim([0.0, 1.0])
      plt.ylim([0.0, 1.05])
      plt.xlabel('Taux de faux positifs (FPR)')
      plt.ylabel('Taux de vrais positifs (TPR)')
      plt.title('Courbe ROC (Receiver Operating Characteristic)')
      plt.legend(loc='lower right')
      plt.show()

    plot_roc_curve(global_labels, global_predictions, classes)

    def plot_loss_accuracy(history):
      # Extraire les données de l'historique
      train_loss = [entry['loss'] for entry in history if 'loss' in entry]
      eval_loss = [entry['eval_loss'] for entry in history if 'eval_loss' in entry]
      train_accuracy = [entry['accuracy'] for entry in history if 'accuracy' in entry]
      eval_accuracy = [entry['eval_accuracy'] for entry in history if 'eval_accuracy' in entry]

      # Tracer la courbe de perte
      plt.subplot(1, 2, 1)
      plt.plot(train_loss, label='Perte Entraînement', color='blue')
      plt.plot(eval_loss, label='Perte Validation', color='red')
      plt.title('Courbe de perte')
      plt.xlabel('Epochs')
      plt.ylabel('Perte')
      plt.legend()

      # Tracer la courbe de précision
      plt.subplot(1, 2, 2)
      plt.plot(train_accuracy, label='Précision Entraînement', color='blue')
      plt.plot(eval_accuracy, label='Précision Validation', color='red')
      plt.title('Courbe de précision')
      plt.xlabel('Epochs')
      plt.ylabel('Précision')
      plt.legend()

      plt.tight_layout()
      plt.show()

    # Appeler cette fonction avec l'historique de l'entraînement
    plot_loss_accuracy(trainer.state.log_history)



    # 9. Sauvegarder le modèle
    model.save_pretrained("models/vit_note_classification")
    feature_extractor.save_pretrained("models/vit_note_classification")
    print("Modèle et extractor sauvegardés sous 'vit_note_classification'.")