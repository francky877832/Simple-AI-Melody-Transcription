import os
import numpy as np
import librosa
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.utils import to_categorical

# 1. Définir le chemin vers le dataset
DATASET_PATH = 'path/to/your/dataset'  # Remplacez par le chemin réel

# 2. Paramètres de l'extraction des caractéristiques
SAMPLE_RATE = 22050  # Taux d'échantillonnage
DURATION = 2.0       # Durée des clips audio en secondes
SAMPLES_PER_TRACK = int(SAMPLE_RATE * DURATION)

# 3. Fonctions pour extraire les MFCC
def extract_features(file_path, max_pad_len=40):
    try:
        audio, sr = librosa.load(file_path, sr=SAMPLE_RATE, duration=DURATION)
        if len(audio) < SAMPLES_PER_TRACK:
            padding = SAMPLES_PER_TRACK - len(audio)
            audio = np.pad(audio, (0, padding), 'constant')
        else:
            audio = audio[:SAMPLES_PER_TRACK]
        
        # Extraction des MFCC
        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
        mfcc = mfcc.T  # Transposer pour avoir le temps sur l'axe 0

        # Padding pour avoir une taille uniforme
        if mfcc.shape[0] < max_pad_len:
            pad_width = max_pad_len - mfcc.shape[0]
            mfcc = np.pad(mfcc, pad_width=((0, pad_width), (0, 0)), mode='constant')
        else:
            mfcc = mfcc[:max_pad_len]
        
        return mfcc.flatten()
    except Exception as e:
        print(f"Erreur lors du traitement du fichier {file_path}: {e}")
        return None

# 4. Chargement des données et extraction des caractéristiques
def load_data(dataset_path):
    features = []
    labels = []
    for label in os.listdir(dataset_path):
        label_path = os.path.join(dataset_path, label)
        if os.path.isdir(label_path):
            for file in os.listdir(label_path):
                if file.endswith('.wav') or file.endswith('.mp3'):
                    file_path = os.path.join(label_path, file)
                    mfcc = extract_features(file_path)
                    if mfcc is not None:
                        features.append(mfcc)
                        labels.append(label)
    return np.array(features), np.array(labels)

# Charger les données
X, y = load_data(DATASET_PATH)
print(f"Total des échantillons: {X.shape[0]}")

# 5. Encodage des labels
le = LabelEncoder()
y_encoded = le.fit_transform(y)
y_categorical = to_categorical(y_encoded)

# 6. Normalisation des caractéristiques
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 7. Séparation en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y_categorical, test_size=0.2, random_state=42, stratify=y_categorical
)

print(f"Entraînement: {X_train.shape[0]} échantillons")
print(f"Test: {X_test.shape[0]} échantillons")

# 8. Construction du modèle
num_classes = y_categorical.shape[1]
model = Sequential([
    Dense(256, input_shape=(X_train.shape[1],), activation='relu'),
    Dropout(0.5),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(num_classes, activation='softmax')
])

# 9. Compilation du modèle
model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

# 10. Entraînement du modèle
history = model.fit(
    X_train, y_train,
    epochs=100,
    batch_size=32,
    validation_data=(X_test, y_test),
    verbose=1
)

# 11. Évaluation du modèle
loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f"Précision sur l'ensemble de test: {accuracy * 100:.2f}%")

# 12. Sauvegarder le modèle et le LabelEncoder pour une utilisation future
model.save('model_notes_guitare.h5')
import joblib
joblib.dump(le, 'label_encoder.pkl')
joblib.dump(scaler, 'scaler.pkl')






from tensorflow.keras.models import load_model
import joblib

# Charger le modèle et les objets d'encodage
model = load_model('model_notes_guitare.h5')
le = joblib.load('label_encoder.pkl')
scaler = joblib.load('scaler.pkl')

# Fonction de prédiction
def predict_note(file_path):
    mfcc = extract_features(file_path)
    if mfcc is not None:
        mfcc_scaled = scaler.transform([mfcc])
        prediction = model.predict(mfcc_scaled)
        predicted_label = le.inverse_transform([np.argmax(prediction)])
        return predicted_label[0]
    else:
        return None

# Exemple d'utilisation
new_file = 'path/to/new/audio.wav'
predicted_note = predict_note(new_file)
print(f"La note prédite est : {predicted_note}")
